{"meta":{"title":"个人博客","subtitle":"java","description":"编程日记","author":"wys","url":"http://yoursite.com","root":"/"},"pages":[{"title":"分类","date":"2019-04-24T07:30:30.000Z","updated":"2020-06-15T04:55:51.565Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-04-24T07:40:24.000Z","updated":"2020-06-15T04:56:02.422Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"springCloud系列（3）之Zuul网关","slug":"springCloud系列（3）之Zuul网关","date":"2020-06-15T07:28:52.242Z","updated":"2020-05-27T03:10:35.407Z","comments":true,"path":"2020/06/15/springCloud系列（3）之Zuul网关/","link":"","permalink":"http://yoursite.com/2020/06/15/springCloud%E7%B3%BB%E5%88%97%EF%BC%883%EF%BC%89%E4%B9%8BZuul%E7%BD%91%E5%85%B3/","excerpt":"","text":"Zuul网关， 作用： 提供统一的对外入口，识别权限，动态路由。 当访问zuul项目是会根据配置自动访问对应服务，通过这种方式进行统一的路由配置 环境搭建1、创建zuul项目 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt; &lt;groupId&gt;com.lihao&lt;&#x2F;groupId&gt; &lt;artifactId&gt;cloud-order&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt; &lt;version&gt;1.5.6.RELEASE&lt;&#x2F;version&gt; &lt;relativePath&#x2F;&gt; &lt;!-- lookup parent from repository --&gt; &lt;&#x2F;parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;&#x2F;project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;&#x2F;java.version&gt; &lt;&#x2F;properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;&#x2F;artifactId&gt; &lt;scope&gt;test&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.5.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;!-- zuul网关 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;scope&gt;runtime&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.2&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;!-- hystrix 监视器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.5.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;&#x2F;artifactId&gt; &lt;version&gt;Dalston.SR4&lt;&#x2F;version&gt; &lt;type&gt;pom&lt;&#x2F;type&gt; &lt;scope&gt;import&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; &lt;&#x2F;dependencyManagement&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src&#x2F;main&#x2F;java&lt;&#x2F;directory&gt; &lt;excludes&gt; &lt;exclude&gt;**&#x2F;*.java&lt;&#x2F;exclude&gt; &lt;&#x2F;excludes&gt; &lt;&#x2F;resource&gt; &lt;resource&gt; &lt;directory&gt;src&#x2F;main&#x2F;resources&lt;&#x2F;directory&gt; &lt;includes&gt; &lt;include&gt;**&#x2F;*.*&lt;&#x2F;include&gt; &lt;&#x2F;includes&gt; &lt;&#x2F;resource&gt; &lt;&#x2F;resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt; &lt;&#x2F;plugin&gt; &lt;&#x2F;plugins&gt; &lt;&#x2F;build&gt;&lt;&#x2F;project&gt; 2、创建启动类 123456789@SpringBootApplication@EnableZuulProxypublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class,args); &#125;&#125; 3、创建配置文件application.yml 1234567891011121314server: port: 8079spring: application: name: cloud-zuuleureka: client: service-url: defaultZone: http:&#x2F;&#x2F;root:123456@localhost:7776&#x2F;eureka&#x2F;zuul: routes: cloud-order: path: &#x2F;cloud-order&#x2F;** #当访问该路径时会跳转到user-consumer服务中 service-id: user-consumer 测试： 访问http://localhost:8079/cloud-order/order/userList，由于之前的配置会自动访问 user-consumer项目中的order/userList路径 自定义filterzuul除了配置共同的网关外，还可以提供分布式自定义拦截器 1、创建PreFilter继承ZuulFilter类重写其中的方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class PreFilter extends ZuulFilter &#123; &#x2F;** * 过滤器类型 * pre：可以在请求被路由之前调用。 * routing：在路由请求时候被调用。 * post：在routing和error过滤器之后被调用。 * error：处理请求时发生错误时被调用 * @return *&#x2F; @Override public String filterType() &#123; return &quot;pre&quot;; &#125; &#x2F;** * 过滤顺序,数值越小优先级越高 * @return *&#x2F; @Override public int filterOrder() &#123; return 0; &#125; &#x2F;** * 是否进行拦截过滤 * @return *&#x2F; @Override public boolean shouldFilter() &#123; return true; &#125; &#x2F;** * 确定需要拦截之后执行的方法 * @return *&#x2F; @Override public Object run() &#123; System.out.println(&quot;经过过滤&quot;); &#x2F;&#x2F; 获得request RequestContext ctx &#x3D; RequestContext.getCurrentContext(); HttpServletRequest request &#x3D; ctx.getRequest(); &#x2F;&#x2F; 获得请求中的参数 String str &#x3D; request.getParameter(&quot;str&quot;); System.out.println(str); return null; &#125;&#125; 2、在启动类中添加配置 1234@Beanpublic PreFilter zuulPreFilter() &#123; return new PreFilter();&#125; 总体来说的画就是这样 1234567891011121314@SpringBootApplication@EnableZuulProxypublic class ZuulApplication &#123; @Bean public PreFilter zuulPreFilter() &#123; return new PreFilter(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class,args); &#125;&#125;","categories":[],"tags":[]},{"title":"springCloud系列（1）之简单入门","slug":"springCloud系列（1）之简单入门","date":"2020-06-15T07:28:52.239Z","updated":"2020-05-27T03:13:16.757Z","comments":true,"path":"2020/06/15/springCloud系列（1）之简单入门/","link":"","permalink":"http://yoursite.com/2020/06/15/springCloud%E7%B3%BB%E5%88%97%EF%BC%881%EF%BC%89%E4%B9%8B%E7%AE%80%E5%8D%95%E5%85%A5%E9%97%A8/","excerpt":"","text":"Eureka， 一个基于 REST 服务的，服务注册与发现的组件 它主要包括两个组件：Eureka Server 和 Eureka Client Eureka Client：一个Java客户端，用于简化与 Eureka Server 的交互（通常就是微服务中的客户端和服务端），注册到Eureka Server上 Eureka Server：提供服务注册和发现的能力（通常就是微服务中的注册中心），有点类似于dubbo中的zookeeper 首先创建server， 创建项目 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt; &lt;groupId&gt;com.lihao&lt;&#x2F;groupId&gt; &lt;artifactId&gt;cloud-eureka-server&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt; &lt;version&gt;1.5.6.RELEASE&lt;&#x2F;version&gt; &lt;relativePath&#x2F;&gt; &lt;!-- lookup parent from repository --&gt; &lt;&#x2F;parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;&#x2F;project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;&#x2F;java.version&gt; &lt;&#x2F;properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;&#x2F;artifactId&gt; &lt;scope&gt;test&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-eureka-server&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.5.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;&#x2F;artifactId&gt; &lt;version&gt;Dalston.SR4&lt;&#x2F;version&gt; &lt;type&gt;pom&lt;&#x2F;type&gt; &lt;scope&gt;import&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; &lt;&#x2F;dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt; &lt;&#x2F;plugin&gt; &lt;&#x2F;plugins&gt; &lt;&#x2F;build&gt;&lt;&#x2F;project&gt; 2、添加EurekaServerApplication启动类 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DmEurekaServerApplication.class, args); &#125;&#125; 3、在resources目录下创建application.yml配置文件 12345678910111213141516server: port: 7776eureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http:&#x2F;&#x2F;localhost:7776&#x2F;eureka&#x2F; server: enable-self-preservation: falsesecurity: basic: enabled: true user: name: root password: 123456 然后就可以启动了，运行EurekaServerApplication即可，然后访问localhost:7776，可以看到注册界面就说明启动成功， 接下来就开始编写客户端，把服务注册到该server，注意，这里的生产者和消费者都是基于springBoot+Mybatis环境的项目，cloud-user提供对user表的操作是生产者，cloud-order调用cloud-user里面的关于userService是消费者 编写生产者provider创建cloud-user 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt; &lt;groupId&gt;com.lihao&lt;&#x2F;groupId&gt; &lt;artifactId&gt;cloud-user&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;&#x2F;version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt; &lt;version&gt;1.5.6.RELEASE&lt;&#x2F;version&gt; &lt;relativePath&#x2F;&gt; &lt;!-- lookup parent from repository --&gt; &lt;&#x2F;parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;&#x2F;project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;&#x2F;java.version&gt; &lt;&#x2F;properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;&#x2F;artifactId&gt; &lt;scope&gt;test&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.5.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt; &lt;scope&gt;runtime&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.2&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;&#x2F;artifactId&gt; &lt;version&gt;Dalston.SR4&lt;&#x2F;version&gt; &lt;type&gt;pom&lt;&#x2F;type&gt; &lt;scope&gt;import&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; &lt;&#x2F;dependencyManagement&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src&#x2F;main&#x2F;java&lt;&#x2F;directory&gt; &lt;excludes&gt; &lt;exclude&gt;**&#x2F;*.java&lt;&#x2F;exclude&gt; &lt;&#x2F;excludes&gt; &lt;&#x2F;resource&gt; &lt;resource&gt; &lt;directory&gt;src&#x2F;main&#x2F;resources&lt;&#x2F;directory&gt; &lt;includes&gt; &lt;include&gt;**&#x2F;*.*&lt;&#x2F;include&gt; &lt;&#x2F;includes&gt; &lt;&#x2F;resource&gt; &lt;&#x2F;resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt; &lt;&#x2F;plugin&gt; &lt;&#x2F;plugins&gt; &lt;&#x2F;build&gt;&lt;&#x2F;project&gt; 创建UserApplication启动类 123456789@SpringBootApplication@MapperScan(basePackages&#x3D;&quot;lihao.dao&quot;)@EnableDiscoveryClientpublic class UserApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UserApplication.class,args); &#125;&#125; 关于其他的controller，mybatis的mapper，实体类等代码这里就不沾出来了，这里主要记录重要的代码 1234567891011121314151617181920@Service@RestController // 这里注意public class UserServiceImpl implements UserService &#123; @Autowired @SuppressWarnings(\"all\") private UserMapper userMapper; // 还有这里 @RequestMapping(value = \"/getList\", method = RequestMethod.GET) public List&lt;User&gt; getList() &#123; System.out.println(\"这里userService\"); return userMapper.findAll(); &#125; @Override public int insert(String name) &#123; return userMapper.insert(name); &#125;&#125; resources目录下创建application.yml配置文件 1234567891011121314151617server: port: 8081spring: application: name: user-provider datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;ssm?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false password: root username: rootmybatis: type-aliases-package: lihao mapper-locations: classes:mapper&#x2F;*Mapper.xmleureka: client: service-url: defaultZone: http:&#x2F;&#x2F;root:123456@localhost:7776&#x2F;eureka&#x2F; 创建消费者consumerpom文件和cloud-user一致，这里不再沾出，直接编写启动类OrderApplication 123456789@SpringBootApplication@MapperScan(basePackages&#x3D;&quot;lihao.dao&quot;)@EnableDiscoveryClient@EnableFeignClients &#x2F;&#x2F;使用Feignpublic class OrderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderApplication.class,args); &#125;&#125; 创建UserService用于调用生产者的服务，并使用注解引用 12345678@FeignClient(name &#x3D; &quot;user-provider&quot;) &#x2F;&#x2F; 生产者名称public interface UserService &#123; &#x2F;&#x2F; 服务名称 @RequestMapping(value &#x3D; &quot;&#x2F;getList&quot;,method &#x3D; RequestMethod.GET) public List&lt;User&gt; getList();&#125; 开始使用 12345678910111213@RestController@RequestMapping(&quot;&#x2F;order&quot;)public class OrderController &#123; @Autowired private UserService userService; @RequestMapping(&quot;&#x2F;userList&quot;) public List&lt;User&gt; userList()&#123; return userService.getList(); &#125;&#125; 别忘了配置文件 1234567891011121314151617server: port: 8080spring: application: name: user-consumer datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;ssm?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false password: root username: rootmybatis: type-aliases-package: lihao mapper-locations: classes:mapper&#x2F;*Mapper.xmleureka: client: service-url: defaultZone: http:&#x2F;&#x2F;root:123456@localhost:7776&#x2F;eureka&#x2F; 然后启动就好，当访问http://localhost:8080/order/userList可以获得相关用户记录就好","categories":[],"tags":[]},{"title":"springCloud系列（1）之Hystrix容错机制","slug":"springCloud系列（1）之Hystrix容错机制","date":"2020-06-15T07:28:52.236Z","updated":"2020-05-27T03:10:34.533Z","comments":true,"path":"2020/06/15/springCloud系列（1）之Hystrix容错机制/","link":"","permalink":"http://yoursite.com/2020/06/15/springCloud%E7%B3%BB%E5%88%97%EF%BC%881%EF%BC%89%E4%B9%8BHystrix%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6/","excerpt":"","text":"Hystrix 服务熔断机制，当服务提供者服务出现异常时的操作，当服务出错后会自动进入到错误处理的方法 服务消费者，只需要在消费者端处理即可 创建UserFallback类用于异常处理，注意UserFallback需要实现UserService接口，这里的UserService指的是针对哪一个服务接口进行的熔断处理，针对哪个接口就需要实现这个接口 12345678910@Componentpublic class UserFallback implements UserService&#123; @Override public List&lt;User&gt; getList() &#123; System.out.println(&quot;服务异常，稍后重试&quot;); return null; &#125;&#125; 然后在服务上声明fallback 1234567@FeignClient(name &#x3D; &quot;user-provider&quot;,fallback &#x3D; UserFallback.class)public interface UserService &#123; @RequestMapping(value &#x3D; &quot;&#x2F;getList&quot;,method &#x3D; RequestMethod.GET) public List&lt;User&gt; getList(); &#125; 最后修改配置文件application.yml，增加 123feign: hystrix: enabled: true 然后照旧调用服务即可 12345678910111213@RestController@RequestMapping(&quot;&#x2F;order&quot;)public class OrderController &#123; @Autowired @SuppressWarnings(&quot;All&quot;) private UserService userService; @RequestMapping(&quot;&#x2F;userList&quot;) public List&lt;User&gt; userList()&#123; return userService.getList(); &#125;&#125; 这时候就会执行UserFallback中的方法，不管是服务报错还是提供者断掉都会去执行","categories":[],"tags":[]},{"title":"RabbitMQ的使用","slug":"RabbitMQ的使用","date":"2020-06-15T07:28:52.234Z","updated":"2020-05-27T03:09:27.645Z","comments":true,"path":"2020/06/15/RabbitMQ的使用/","link":"","permalink":"http://yoursite.com/2020/06/15/RabbitMQ%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"RabbitMQ ，也是消息队列 使用RabbitMQ 实现分布式事务 RabbitMQ是使用Erlang语言来编写的 ，所以需要安装Erlang环境 安装完成后会在服务中开启rabbitMQ服务 然后再浏览器访问http://localhost:15672/#/ 就可以看到rabbitMQ的控制器 使用默认账号登录：guest/ guest AMQP protocol version mismatch; we are version 0-9-1, server sent signature 3,1,0,0 服务器上同时启动了activeMQ，关掉就好 测试： 首先启动消息生产者，调用send方法访问，否则无法启动消费者项目，接受者能接受到数据则说明搭建成功 发送者 12345&lt;!--rabbitMQ--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 配置文件 123456spring: rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest 123456789@Configurationpublic class RabbitConfig &#123; @Bean public Queue queue() &#123; return new Queue(&quot;q_hello&quot;); &#125;&#125; Controller中 1234567891011121314@Autowiredprivate AmqpTemplate rabbitTemplate;@GetMapping(&quot;send&quot;)@ResponseBodypublic String send()&#123; String date &#x3D; new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).format(new Date());&#x2F;&#x2F;24小时制 String context &#x3D; &quot;hello &quot; + date; System.out.println(&quot;发送的数据 : &quot; + context); &#x2F;&#x2F;简单对列的情况下routingKey即为Q名 this.rabbitTemplate.convertAndSend(&quot;q_hello&quot;, context); return &quot;SUCCESS&quot;;&#125; 接收者 12345678910@Component@RabbitListener(queues &#x3D; &quot;q_hello&quot;)public class RabbitUtil &#123; @RabbitHandler public void process(String hello) &#123; System.out.println(&quot;接收到的数据 : &quot; + hello); &#125;&#125;","categories":[],"tags":[]},{"title":"RabbitMQ的使用(2)","slug":"RabbitMQ的使用(2)","date":"2020-06-15T07:28:52.230Z","updated":"2020-05-27T03:09:24.022Z","comments":true,"path":"2020/06/15/RabbitMQ的使用(2)/","link":"","permalink":"http://yoursite.com/2020/06/15/RabbitMQ%E7%9A%84%E4%BD%BF%E7%94%A8(2)/","excerpt":"","text":"RabbitMQ ，也是消息队列 使用RabbitMQ 实现分布式事务 RabbitMQ是使用Erlang语言来编写的 ，所以需要安装Erlang环境 安装完成后会在服务中开启rabbitMQ服务 然后再浏览器访问http://localhost:15672/#/ 就可以看到rabbitMQ的控制器 使用默认账号登录：guest/ guest 无法访问后台的话，需要进入sbin目录下运行下面命令 1rabbitmq-plugins enable rabbitmq_management AMQP protocol version mismatch; we are version 0-9-1, server sent signature 3,1,0,0 服务器上同时启动了activeMQ，关掉就好 测试： 首先启动消息生产者，调用send方法访问，否则无法启动消费者项目，接受者能接受到数据则说明搭建成功 发送者 12345&lt;!--rabbitMQ--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 生产者配置文件 123456spring: rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest 123456789@Configurationpublic class RabbitConfig &#123; @Bean public Queue queue() &#123; return new Queue(&quot;q_hello&quot;); &#125;&#125; Controller中 1234567891011121314@Autowiredprivate AmqpTemplate rabbitTemplate;@GetMapping(&quot;send&quot;)@ResponseBodypublic String send()&#123; String date &#x3D; new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).format(new Date());&#x2F;&#x2F;24小时制 String context &#x3D; &quot;hello &quot; + date; System.out.println(&quot;发送的数据 : &quot; + context); &#x2F;&#x2F;简单对列的情况下routingKey即为Q名 this.rabbitTemplate.convertAndSend(&quot;q_hello&quot;, context); return &quot;SUCCESS&quot;;&#125; 接收者 12345678910@Component@RabbitListener(queues &#x3D; &quot;q_hello&quot;)public class RabbitUtil &#123; @RabbitHandler public void process(String hello) &#123; System.out.println(&quot;接收到的数据 : &quot; + hello); &#125;&#125; 异常：无法创建data目录，用户名中文造成乱码问题 在环境变量中添加 RABBITMQ_BASE 环境变量，值是rabbitMQ数据的地址目录 重新安装rabbit就好 confirm消息确认机制rabbitMQ另一特色消息确认机制，通过消息回掉确认是否收到消息 通道： 消息： 1、添加配置 1234567891011spring: rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest publisher-confirms: true publisher-returns: true listener: simple: acknowledge-mode: manual 2、发送者配置类 123456789101112131415161718192021@Configurationpublic class RabbitConfig &#123; &#x2F;&#x2F; 创建交换机 @Bean public TopicExchange topicExchange() &#123; return new TopicExchange(&quot;message_confirm_exchange&quot;); &#125; &#x2F;&#x2F; 创建消息 @Bean public Queue queue() &#123; return new Queue(&quot;q_hello&quot;); &#125; &#x2F;&#x2F; 绑定交换机和消息 ？routingKey 作用 @Bean public Binding bindingDirect() &#123; return BindingBuilder.bind(queue()).to(topicExchange()).with(&quot;user.#&quot;); &#125;&#125; 3、创建CustomConfirmAndReturnCallback类编写confirm响应消息 123456789101112131415161718192021222324252627282930313233343536373839404142@Componentpublic class CustomConfirmAndReturnCallback implements RabbitTemplate.ConfirmCallback, RabbitTemplate.ReturnCallback &#123; @Autowired private RabbitTemplate rabbitTemplate; &#x2F;** * PostConstruct: 用于在依赖关系注入完成之后需要执行的方法上，以执行任何初始化. *&#x2F; @PostConstruct public void init() &#123; &#x2F;&#x2F;指定 ConfirmCallback rabbitTemplate.setConfirmCallback(this); &#x2F;&#x2F;指定 ReturnCallback rabbitTemplate.setReturnCallback(this); &#125; &#x2F;** * 消息从交换机成功到达队列，则returnedMessage方法不会执行; * 消息从交换机未能成功到达队列，则returnedMessage方法会执行; *&#x2F; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; System.out.println(&quot;returnedMessage回调方法&gt;&gt;&gt;&quot; + new String(message.getBody(), StandardCharsets.UTF_8) + &quot;,replyCode:&quot; + replyCode + &quot;,replyText:&quot; + replyText + &quot;,exchange:&quot; + exchange + &quot;,routingKey:&quot; + routingKey); &#125; &#x2F;** * 如果消息没有到达交换机,则该方法中isSendSuccess &#x3D; false,error为错误信息; * 如果消息正确到达交换机,则该方法中isSendSuccess &#x3D; true; *&#x2F; @Override public void confirm(CorrelationData correlationData, boolean isSendSuccess, String error) &#123; &#x2F;&#x2F;System.out.println(&quot;confirm回调方法&gt;&gt;&gt;回调消息ID为: &quot; + correlationData.getId()); if (isSendSuccess) &#123; System.out.println(&quot;confirm回调方法&gt;&gt;&gt;消息发送到交换机成功！&quot;); &#125; else &#123; System.out.println(&quot;confirm回调方法&gt;&gt;&gt;消息发送到交换机失败！，原因 : &quot;+error); &#125; &#125;&#125; 4、发送者发送消息，在controller中调用访问send路径，发送消息 123456789101112131415@Autowired private AmqpTemplate rabbitTemplate;@GetMapping(&quot;send&quot;) @ResponseBody public String send()&#123; String date &#x3D; new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).format(new Date());&#x2F;&#x2F;24小时制 String context &#x3D; &quot;hello &quot; + date; System.out.println(&quot;发送的数据 : &quot; + context); &#x2F;&#x2F;简单对列的情况下routingKey即为Q名 CorrelationData correlationData &#x3D; new CorrelationData(); this.rabbitTemplate.convertAndSend(&quot;message_confirm_exchange&quot;, context); return &quot;SUCCESS&quot;; &#125; 5、编写接受者 123456789101112131415161718192021222324@Component@RabbitListener(queues &#x3D; &quot;q_hello&quot;)public class RabbitUtil &#123; @RabbitHandler public void process(String hello, Channel channel, Message message) &#123; System.out.println(&quot;接收到的数据 : &quot; + hello); try &#123; if(true)&#123;throw new NullPointerException();&#125; &#x2F;&#x2F; 返回正确响应 channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; catch (Exception e) &#123; try &#123; &#x2F;&#x2F; 返回拒绝响应 channel.basicNack(message.getMessageProperties().getDeliveryTag(), false,false); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; e.printStackTrace(); &#125; &#125;&#125;","categories":[],"tags":[]},{"title":"RabbitMQ的使用(1)","slug":"RabbitMQ的使用(1)","date":"2020-06-15T07:28:52.228Z","updated":"2020-05-27T03:10:57.047Z","comments":true,"path":"2020/06/15/RabbitMQ的使用(1)/","link":"","permalink":"http://yoursite.com/2020/06/15/RabbitMQ%E7%9A%84%E4%BD%BF%E7%94%A8(1)/","excerpt":"","text":"RabbitMQ ，也是消息队列 使用RabbitMQ 实现分布式事务 RabbitMQ是使用Erlang语言来编写的 ，所以需要安装Erlang环境 安装完成后会在服务中开启rabbitMQ服务 然后再浏览器访问http://localhost:15672/#/ 就可以看到rabbitMQ的控制器 使用默认账号登录：guest/ guest AMQP protocol version mismatch; we are version 0-9-1, server sent signature 3,1,0,0 服务器上同时启动了activeMQ，关掉就好 测试： 首先启动消息生产者，调用send方法访问，否则无法启动消费者项目，接受者能接受到数据则说明搭建成功 发送者 12345&lt;!--rabbitMQ--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 配置文件 123456spring: rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest 123456789@Configurationpublic class RabbitConfig &#123; @Bean public Queue queue() &#123; return new Queue(&quot;q_hello&quot;); &#125;&#125; Controller中 1234567891011121314@Autowiredprivate AmqpTemplate rabbitTemplate;@GetMapping(&quot;send&quot;)@ResponseBodypublic String send()&#123; String date &#x3D; new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).format(new Date());&#x2F;&#x2F;24小时制 String context &#x3D; &quot;hello &quot; + date; System.out.println(&quot;发送的数据 : &quot; + context); &#x2F;&#x2F;简单对列的情况下routingKey即为Q名 this.rabbitTemplate.convertAndSend(&quot;q_hello&quot;, context); return &quot;SUCCESS&quot;;&#125; 接收者 12345678910@Component@RabbitListener(queues &#x3D; &quot;q_hello&quot;)public class RabbitUtil &#123; @RabbitHandler public void process(String hello) &#123; System.out.println(&quot;接收到的数据 : &quot; + hello); &#125;&#125;","categories":[],"tags":[]},{"title":"mycat的使用","slug":"mycat的使用","date":"2020-06-15T07:28:52.226Z","updated":"2020-05-27T03:09:20.095Z","comments":true,"path":"2020/06/15/mycat的使用/","link":"","permalink":"http://yoursite.com/2020/06/15/mycat%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"image-20200331194234063 数据切分：按照特定的条件，把存入一个数据的数据存到多个数据库（主机）上，数据的切分可以按照两种切分方式， ​ 数据垂直切分：按照不同的表分到不同主机上。 ​ 数据水平切分：一个表中的不同数据进行拆分到不同的主机上 mycat，一个开源的分布式数据库系统，核心功能是分库分表，把一张大表分成多个小表，针对于开发者来说mycat就是一个数据库服务器，可以使用连接MySQL的方式连接，然后管理MySQL，一个强大的数据库中间件。 原理：重点拦截，拦截发送给MySQL数据库的SQL语句，然后进行分析处理，最后发送给不同的主机 应用场景：1、单纯的读写分离，此时配置最为简单，支持读写分离，主从切换； 2、分表分库，对于超过 1000 万的表进行分片，最大支持 1000 亿的单表分片； 3、多租户应用，每个应用一个库，但应用程序只连接 Mycat，从而不改造程序本身，实现多租户化； 4、报表系统，借助于 Mycat 的分表能力，处理大规模报表的统计； 5、替代 Hbase，分析大数据； 6、作为海量数据实时查询的一种简单有效方案，比如 100 亿条频繁查询的记录需要在 3 秒内查询出来结果， 除了基于主键的查询，还可能存在范围查询或其他属性查询，此时 Mycat 可能是最简单有效的选择 重要概念：0、逻辑库/表：mycat中存在的库和表 1、分片表：原本有大量数据的表 2、ER表：关系表 3、全局表：类似于字典表这种表，字典表和很多表都有关联，mycat采用数据冗余存储 4、分片节点（dataNode）：一张大表分为多个数据库上，每个数据库就是分片节点 5、分片主机（dataHost）：分片节点可以在不同的主机，一个或者多个节点所在的主机就是分片主机 6、分片规则（rule）：数据划分的规则 7、全局序列号：数据切分后原本的主键就无法使用了，因此需要引入一个值保证数据唯一性。 8、多租户（很重要）：多个环境下公用相同的系统，并且保证隔离性 ​ 8-1：独立数据库，隔离性高，但是代价比较庞大 ​ 8-2：共享一个数据库，不是完全隔离，隔离性不高，容易出错 ​ 8-3：共用数据结构，数据架构，通过ID进行区分租户数据（也就是用mycat） 安装注意先安装Java环境以及MySQL数据库 安装包解压 进入bin目录下，双击运行startup_nowrap.bat 启动后可以使用native连接mycat，连接端口是8066 使用Schema.xml 作为 MyCat 中重要的配置文件之一，管理着 MyCat 的逻辑库、表、分片规则、DataNode 以及 DataSource。 1234567891011121314151617181920212223242526272829303132schema 配置表 table primaryKey 真实表主键 rule 分片规则，在rule.xml中定义 常用分片规则 分片枚举（hash-int）：在配置文件中配置可能出现的枚举id，配置分片 固定分片Hash算法（func1）：二进制操作的求模运算 范围约定（rang-long）：提前规定好字段范围属于哪个分片 取模（mod-long）：根据ID进行10进制的求模运算 日期分片（sharding-by-date）：按照时间划分 取模范围（sharding-by-pattern）：按照取模运算和范围运算结合 应用指定（sharding-by-substring）：运行阶段有应用自主决定路由到那个分片 。。。。。dataNode 配置数据节点dataHost 配置数据库连接，读写分离和心跳语句 balance 负载均衡类型 1. balance&#x3D;“0”, 所有读操作都发送到当前可用的writeHost上。 2. balance&#x3D;“1”，所有读操作都随机的发送到readHost。 3. balance&#x3D;“2”，所有读操作都随机的在writeHost、readhost上分发。 writeType 写的负载均衡 1. writeType&#x3D;“0”, 所有写操作都发送到可用的writeHost上。 2. writeType&#x3D;“1”，所有写操作都随机的发送到readHost。 3. writeType&#x3D;“2”，所有写操作都随机的在writeHost、readhost分上发。 heartbeat 心跳检查语句 writeHost标签、readHost标签 连接数据库，writeHost指定写实例、readHost指定读实例 rule.xml 配置分表规则 1234567tableRule 分表规则 columns 针对哪一个列进行拆分 algorithm function中的name，指定分表具体算法function 分表算法 class 路由算法具体类 property 算法需要用到的参数","categories":[],"tags":[]},{"title":"mycat的使用(1)","slug":"mycat的使用(1)","date":"2020-06-15T07:28:52.223Z","updated":"2020-05-27T03:09:20.159Z","comments":true,"path":"2020/06/15/mycat的使用(1)/","link":"","permalink":"http://yoursite.com/2020/06/15/mycat%E7%9A%84%E4%BD%BF%E7%94%A8(1)/","excerpt":"","text":"image-20200331194234063 数据切分：按照特定的条件，把存入一个数据的数据存到多个数据库（主机）上，数据的切分可以按照两种切分方式， ​ 数据垂直切分：按照不同的表分到不同主机上。 ​ 数据水平切分：一个表中的不同数据进行拆分到不同的主机上 mycat，一个开源的分布式数据库系统，核心功能是分库分表，把一张大表分成多个小表，针对于开发者来说mycat就是一个数据库服务器，可以使用连接MySQL的方式连接，然后管理MySQL，一个强大的数据库中间件。 原理：重点拦截，拦截发送给MySQL数据库的SQL语句，然后进行分析处理，最后发送给不同的主机 应用场景：1、单纯的读写分离，此时配置最为简单，支持读写分离，主从切换； 2、分表分库，对于超过 1000 万的表进行分片，最大支持 1000 亿的单表分片； 3、多租户应用，每个应用一个库，但应用程序只连接 Mycat，从而不改造程序本身，实现多租户化； 4、报表系统，借助于 Mycat 的分表能力，处理大规模报表的统计； 5、替代 Hbase，分析大数据； 6、作为海量数据实时查询的一种简单有效方案，比如 100 亿条频繁查询的记录需要在 3 秒内查询出来结果， 除了基于主键的查询，还可能存在范围查询或其他属性查询，此时 Mycat 可能是最简单有效的选择 重要概念：0、逻辑库/表：mycat中存在的库和表 1、分片表：原本有大量数据的表 2、ER表：关系表 3、全局表：类似于字典表这种表，字典表和很多表都有关联，mycat采用数据冗余存储 4、分片节点（dataNode）：一张大表分为多个数据库上，每个数据库就是分片节点 5、分片主机（dataHost）：分片节点可以在不同的主机，一个或者多个节点所在的主机就是分片主机 6、分片规则（rule）：数据划分的规则 7、全局序列号：数据切分后原本的主键就无法使用了，因此需要引入一个值保证数据唯一性。 8、多租户（很重要）：多个环境下公用相同的系统，并且保证隔离性 ​ 8-1：独立数据库，隔离性高，但是代价比较庞大 ​ 8-2：共享一个数据库，不是完全隔离，隔离性不高，容易出错 ​ 8-3：共用数据结构，数据架构，通过ID进行区分租户数据（也就是用mycat） 安装注意先安装Java环境以及MySQL数据库 安装包解压 进入bin目录下，双击运行startup_nowrap.bat 启动后可以使用native连接mycat，连接端口是8066 使用Schema.xml 作为 MyCat 中重要的配置文件之一，管理着 MyCat 的逻辑库、表、分片规则、DataNode 以及 DataSource。 1234567891011121314151617181920212223242526272829303132schema 配置表 table primaryKey 真实表主键 rule 分片规则，在rule.xml中定义 常用分片规则 分片枚举（hash-int）：在配置文件中配置可能出现的枚举id，配置分片 固定分片Hash算法（func1）：二进制操作的求模运算 范围约定（rang-long）：提前规定好字段范围属于哪个分片 取模（mod-long）：根据ID进行10进制的求模运算 日期分片（sharding-by-date）：按照时间划分 取模范围（sharding-by-pattern）：按照取模运算和范围运算结合 应用指定（sharding-by-substring）：运行阶段有应用自主决定路由到那个分片 。。。。。dataNode 配置数据节点dataHost 配置数据库连接，读写分离和心跳语句 balance 负载均衡类型 1. balance&#x3D;“0”, 所有读操作都发送到当前可用的writeHost上。 2. balance&#x3D;“1”，所有读操作都随机的发送到readHost。 3. balance&#x3D;“2”，所有读操作都随机的在writeHost、readhost上分发。 writeType 写的负载均衡 1. writeType&#x3D;“0”, 所有写操作都发送到可用的writeHost上。 2. writeType&#x3D;“1”，所有写操作都随机的发送到readHost。 3. writeType&#x3D;“2”，所有写操作都随机的在writeHost、readhost分上发。 heartbeat 心跳检查语句 writeHost标签、readHost标签 连接数据库，writeHost指定写实例、readHost指定读实例 rule.xml 配置分表规则 1234567tableRule 分表规则 columns 针对哪一个列进行拆分 algorithm function中的name，指定分表具体算法function 分表算法 class 路由算法具体类 property 算法需要用到的参数 多表操作 select * from 表1 inner join 表2 on 连接条件 表1的数据在db1 表2的数据在db2 1234&lt;table name&#x3D;&quot;demo&quot; primaryKey&#x3D;&quot;id&quot; dataNode&#x3D;&quot;dn1,dn2,dn3&quot; rule&#x3D;&quot;mod-long&quot;&gt; &lt;childTable name&#x3D;&quot;表名&quot; primaryKey&#x3D;&quot;id&quot; joinKey&#x3D;&quot;本表中作为外键的列&quot; parentKey&#x3D;&quot;主表中的列&quot; &#x2F;&gt; &lt;&#x2F;table&gt;","categories":[],"tags":[]},{"title":"kafka的使用","slug":"kafka的使用","date":"2020-06-15T07:28:52.219Z","updated":"2020-05-27T03:09:30.424Z","comments":true,"path":"2020/06/15/kafka的使用/","link":"","permalink":"http://yoursite.com/2020/06/15/kafka%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。 Producer 即生产者，向 Kafka 发送消息，在发送消息时，会根据 Topic 对 消息进行分类。 Consumer 即消费者，通过与 kafka 建立长连接的方式，不断地拉取消息 并对这些消息进行处理。 Topic 即主题，通过对消息指定主题可以将消息分类，消费者可以只关注 自己需要的 Topic 中的消息即可。 每一个主题下可以拥有不同的目录（ partition ），目录的命令是根据主题（Topic）+ 有序序号组成的。 不同于activeMQ消息队列， Kafka 的设计是把所有的 Message 都要写入速度低、容量大的硬盘，以此来换取更强的存储能力 ， 同时因为 Kafka 在磁盘上只做 Sequence I/O （顺序写） ，所以并没有对硬盘带来过大的损失 并且在读取数据的时候改变读取方式，通过0拷贝的方式读取，依次减少读的时间 安装kafka1、下载解压kafka_2.12-2.5.0 2、注意config目录下的server.properties配置文件中属性 12&#x2F;&#x2F; 这里是zookeeper地址，如果是本地的zk使用默认的就行zookeeper.connect&#x3D;localhost:2181 3、双击bin/window下的kafka-server-start.bat文件，注意先开启zk Java 操作 kafka1、jar包 12345&lt;!-- kafka --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-kafka&lt;&#x2F;artifactId&gt; &lt;&#x2F;dependency&gt; 2、发送者 123456789101112&#x2F;* 发送kafka *&#x2F; @Autowired private KafkaTemplate&lt;String, String&gt; KafkaTemplate; @GetMapping(&quot;sendK&quot;) @ResponseBody public String sendMsgToKafka() &#123; KafkaTemplate.send(&quot;message&quot; , &quot;hello,Kafka!&quot;); return &quot;发送消息到Kafka完毕&quot;; &#125; 发送者配置文件 1spring.kafka.producer.bootstrap-servers&#x3D;192.168.2.103:9092 2、接受者 12345678910@KafkaListener(topics &#x3D; &#123;&quot;message&quot;&#125;) public void listen(ConsumerRecord&lt;?, ?&gt; record) &#123; Optional&lt;?&gt; kafkaMessage &#x3D; Optional.ofNullable(record.value()); if (kafkaMessage.isPresent()) &#123; Object message &#x3D; kafkaMessage.get(); System.out.println(&quot;数据接收完毕：&quot;+message); &#125; &#125; 接受者配置文件 12spring.kafka.producer.bootstrap-servers&#x3D;127.0.0.1:9092spring.kafka.consumer.group-id&#x3D;test-consumer-group","categories":[],"tags":[]},{"title":"Elasticsearch使用","slug":"Elasticsearch使用","date":"2020-06-15T07:28:52.216Z","updated":"2020-05-27T03:10:21.000Z","comments":true,"path":"2020/06/15/Elasticsearch使用/","link":"","permalink":"http://yoursite.com/2020/06/15/Elasticsearch%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Elasticsearch 也是基于 Lucene 的搜索引擎应用服务器，采用简单的 RESTfulAPI 来隐藏 Lucene 的复杂性。除此之外，Elasticsearch 对分布式部署提供了很好 的支持，用户不需要过度关注分布式设计的细节，即可实现分布式搜索引擎系统的搭建。因 此本次大觅网开发选用 Elasticsearch 做为搜索引擎服务器来实现商品搜索功能。 总结来说：Elasticsearch 是一个分布式的搜索引擎 其中的相关概念： node节点：单个的Elaticsearch服务器 index索引：相当于关系型数据库中的数据库，注意索引名称小写 document文档：索引中的单条记录称为文档，文档使用的是JSON格式表示 type类型：虚拟的逻辑分组，用于过滤文档，相当于MySQL中的表，不同的是type中只能存储一种数据 文档元数据：文档元数据为 _index, _type，_id，三者用于表示一个文档，index表示文档存放，type表示文档对象类型， id为文档的唯一标识 安装Elaticsearch注意： ​ 1、三个软件版本号要一致 ​ 2、需要先安装JDK环境 下载安装包 解压，在bin目录下双击运行elasticsearch.bat命令，运行完成后访问 http://127.0.0.1:9200/ 端口 获得一个JSON字符串响应说明安装成功，这个是ES的集群信息 然后接下来安装ES的管理工具，有的公司使用的是head组件，其实一个kibana也可以搞定 安装kibana Kibana是一个针对Elasticsearch的开源分析及可视化平台，常提到的大数据日志处理组件ELK里的K ，用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana，可以通过各种图表进行高级数据分析及展示。 下载完成后解压，进入config目录下修改kibana.yml文件，主要注意修改的 1234# ES 的地址，注意可以是集群地址elasticsearch.hosts: [&quot;http:&#x2F;&#x2F;localhost:9200&quot;] # kibana 的语言，修改后展示的是中文界面i18n.locale: &quot;zh-CN&quot; 访问http://localhost:5601 安装logstash用于同步数据源，属于ELK中的L， 将各种格式各种渠道的数据通过它收集解析之后格式化输出到 Elasticsearch ，最后再由 Kibana 提供的比较友好的 Web 界面进行汇总、分析、搜索 下载，解压，注意版本 在bin目录下创建mysqltoes.conf文件用于查询数据库 123456789101112131415161718192021222324252627282930313233# 读取数据input &#123; stdin &#123; &#125; jdbc &#123; jdbc_connection_string &#x3D;&gt; &quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;ssm&quot; jdbc_user &#x3D;&gt; &quot;root&quot; jdbc_password &#x3D;&gt; &quot;root&quot; jdbc_driver_library &#x3D;&gt; &quot;D:&#x2F;ELK&#x2F;logstash-7.6.2&#x2F;bin&#x2F;mysql-connector-java-5.1.38.jar&quot; jdbc_driver_class &#x3D;&gt; &quot;com.mysql.jdbc.Driver&quot; jdbc_paging_enabled &#x3D;&gt; &quot;true&quot; jdbc_page_size &#x3D;&gt; &quot;50000&quot; statement &#x3D;&gt; &quot;SELECT * FROM &#96;user&#96;&quot; schedule &#x3D;&gt; &quot;* * * * *&quot; &#125; &#125; output &#123; stdout &#123; codec &#x3D;&gt; json_lines &#125; elasticsearch &#123; hosts &#x3D;&gt; &quot;localhost:9200&quot; index &#x3D;&gt; &quot;test_user&quot; document_type &#x3D;&gt; &quot;_doc&quot; document_id &#x3D;&gt; &quot;%&#123;id&#125;&quot; &#125;&#125; 12logstash -f mysqltoes.conf一致开着就好，当数据库发生更改是，Elasticsearch中索引也会跟着更新 常规操作GET：以 GET 方式进行请求，一般用于数据查询。 POST：以 POST 方式进行请求，一般用于查询数据、有时也用作新增数据和修改数据。 PUT：以 PUT 方式进行请求，一般用于添加数据、修改数据。 DELETE：以 DELETE 方式进行请求，一般用于删除数据。 123456789101112131415161718添加索引PUT &#x2F;test1 &#123; &quot;settings&quot;:&#123; &quot;number_of_shards&quot;:3, &quot;number_of_replicas&quot;:2 &#125;, &quot;mappings&quot;: &#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125; &#125; &#125;&#125;删除索引DELETE 索引名 文档操作 12345678910111213新增文档POST &#x2F;test1&#x2F;_doc &#123; &quot;name&quot;:&quot;asd&quot;&#125;获取 GET &#x2F;test1&#x2F;_doc&#x2F;nTm5kXEBLntOdeBcP3FH改PUT &#x2F;test1&#x2F;_doc&#x2F;nTm5kXEBLntOdeBcP3FH&#123; &quot;name&quot;:&quot;hello&quot;&#125; 查询操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273查询所有GET &#x2F;goods1&#x2F;_searchmatch 子句 用于匹配度查询GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;name&quot;: &quot;asd&quot; &#125; &#125;&#125;term 精准查询GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;name&quot;: &quot;asd&quot; &#125; &#125;&#125;range 对比大小 “gte”表示”大于等于”、”lte”表示“小于等于”GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; &quot;age&quot;: &#123; “gte”:... ”lte”:... &#125; &#125; &#125;&#125;多个条件查询must：文档必须匹配这些条件才能被包含进来。must_not：文档必须不匹配这些条件才能被包含进来。should：如果文档满足 should 内的条件，将为该文档增加_score，否则，无任何影响GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;name&quot;:&quot;asd&quot; &#125; &#125; ] &#125; &#125;&#125;使用from和size命令分页GET &#x2F;test1&#x2F;_search&#123; &quot;from&quot;: 0, &quot;size&quot;: 20, &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;name&quot;:&quot;asd&quot; &#125; &#125; ] &#125; &#125;&#125; mysql增量更新 中文分词 1234567891011GET _analyze?pretty &#123; &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;text&quot;:&quot;中国人民警察的服务宗旨&quot;&#125;POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;中国人民警察的服务宗旨&quot;&#125; Java操作Elasticsearch","categories":[],"tags":[]},{"title":"Elasticsearch使用(2)","slug":"Elasticsearch使用(2)","date":"2020-06-15T07:28:52.214Z","updated":"2020-05-27T03:10:17.336Z","comments":true,"path":"2020/06/15/Elasticsearch使用(2)/","link":"","permalink":"http://yoursite.com/2020/06/15/Elasticsearch%E4%BD%BF%E7%94%A8(2)/","excerpt":"","text":"Elasticsearch 也是基于 Lucene 的搜索引擎应用服务器，采用简单的 RESTfulAPI 来隐藏 Lucene 的复杂性。除此之外，Elasticsearch 对分布式部署提供了很好 的支持，用户不需要过度关注分布式设计的细节，即可实现分布式搜索引擎系统的搭建。因 此本次大觅网开发选用 Elasticsearch 做为搜索引擎服务器来实现商品搜索功能。 总结来说：Elasticsearch 是一个分布式的搜索引擎 其中的相关概念： node节点：单个的Elaticsearch服务器 index索引：相当于关系型数据库中的数据库，注意索引名称小写 document文档：索引中的单条记录称为文档，文档使用的是JSON格式表示 type类型：虚拟的逻辑分组，用于过滤文档，相当于MySQL中的表，不同的是type中只能存储一种数据 文档元数据：文档元数据为 _index, _type，_id，三者用于表示一个文档，index表示文档存放，type表示文档对象类型， id为文档的唯一标识 安装Elaticsearch注意： ​ 1、三个软件版本号要一致 ​ 2、需要先安装JDK环境 下载安装包 解压，在bin目录下双击运行elasticsearch.bat命令，运行完成后访问 http://127.0.0.1:9200/ 端口 获得一个JSON字符串响应说明安装成功，这个是ES的集群信息 然后接下来安装ES的管理工具，有的公司使用的是head组件，其实一个kibana也可以搞定 安装kibana Kibana是一个针对Elasticsearch的开源分析及可视化平台，常提到的大数据日志处理组件ELK里的K ，用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana，可以通过各种图表进行高级数据分析及展示。 下载完成后解压，进入config目录下修改kibana.yml文件，主要注意修改的 1234# ES 的地址，注意可以是集群地址elasticsearch.hosts: [&quot;http:&#x2F;&#x2F;localhost:9200&quot;] # kibana 的语言，修改后展示的是中文界面i18n.locale: &quot;zh-CN&quot; 访问http://localhost:5601 安装logstash用于同步数据源，属于ELK中的L， 将各种格式各种渠道的数据通过它收集解析之后格式化输出到 Elasticsearch ，最后再由 Kibana 提供的比较友好的 Web 界面进行汇总、分析、搜索 下载，解压，注意版本 在bin目录下创建mysqltoes.conf文件用于查询数据库 123456789101112131415161718192021222324252627282930313233# 读取数据input &#123; stdin &#123; &#125; jdbc &#123; jdbc_connection_string &#x3D;&gt; &quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;ssm&quot; jdbc_user &#x3D;&gt; &quot;root&quot; jdbc_password &#x3D;&gt; &quot;root&quot; jdbc_driver_library &#x3D;&gt; &quot;D:&#x2F;ELK&#x2F;logstash-7.6.2&#x2F;bin&#x2F;mysql-connector-java-5.1.38.jar&quot; jdbc_driver_class &#x3D;&gt; &quot;com.mysql.jdbc.Driver&quot; jdbc_paging_enabled &#x3D;&gt; &quot;true&quot; jdbc_page_size &#x3D;&gt; &quot;50000&quot; statement &#x3D;&gt; &quot;SELECT * FROM &#96;user&#96;&quot; schedule &#x3D;&gt; &quot;* * * * *&quot; &#125; &#125; output &#123; stdout &#123; codec &#x3D;&gt; json_lines &#125; elasticsearch &#123; hosts &#x3D;&gt; &quot;localhost:9200&quot; index &#x3D;&gt; &quot;test_user&quot; document_type &#x3D;&gt; &quot;_doc&quot; document_id &#x3D;&gt; &quot;%&#123;id&#125;&quot; &#125;&#125; 12logstash -f mysqltoes.conf一致开着就好，当数据库发生更改是，Elasticsearch中索引也会跟着更新 常规操作GET：以 GET 方式进行请求，一般用于数据查询。 POST：以 POST 方式进行请求，一般用于查询数据、有时也用作新增数据和修改数据。 PUT：以 PUT 方式进行请求，一般用于添加数据、修改数据。 DELETE：以 DELETE 方式进行请求，一般用于删除数据。 123456789101112131415161718添加索引PUT &#x2F;test1 &#123; &quot;settings&quot;:&#123; &quot;number_of_shards&quot;:3, &quot;number_of_replicas&quot;:2 &#125;, &quot;mappings&quot;: &#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125; &#125; &#125;&#125;删除索引DELETE 索引名 文档操作 12345678910111213新增文档POST &#x2F;test1&#x2F;_doc &#123; &quot;name&quot;:&quot;asd&quot;&#125;获取 GET &#x2F;test1&#x2F;_doc&#x2F;nTm5kXEBLntOdeBcP3FH改PUT &#x2F;test1&#x2F;_doc&#x2F;nTm5kXEBLntOdeBcP3FH&#123; &quot;name&quot;:&quot;hello&quot;&#125; 查询操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374查询所有GET &#x2F;goods1&#x2F;_searchmatch 子句 用于匹配度查询GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;name&quot;: &quot;asd&quot; &#125; &#125;&#125;term 精准查询term ？？？ GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;name&quot;: &quot;asd&quot; &#125; &#125;&#125;range 对比大小 “gte”表示”大于等于”、”lte”表示“小于等于”GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; &quot;age&quot;: &#123; “gte”:... ”lte”:... &#125; &#125; &#125;&#125;多个条件查询must：文档必须匹配这些条件才能被包含进来。must_not：文档必须不匹配这些条件才能被包含进来。should：如果文档满足 should 内的条件，将为该文档增加_score，否则，无任何影响GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;name&quot;:&quot;asd&quot; &#125; &#125; ] &#125; &#125;&#125;使用from和size命令分页GET &#x2F;test1&#x2F;_search&#123; &quot;from&quot;: 0, &quot;size&quot;: 20, &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;name&quot;:&quot;asd&quot; &#125; &#125; ] &#125; &#125;&#125; mysql增量更新 123456781、修改数据库，增加时间列update_date，这里列主要用于记录数据更新时间，然后根据更新时间作为条件判断，判断是否更新数据到ES2、修改config配置use_column_value &#x3D;&gt; falsejdbc_default_timezone &#x3D;&gt;&quot;Asia&#x2F;Shanghai&quot;statement &#x3D;&gt; &quot;SELECT * FROM &#96;user&#96; update_date &gt; :sql_last_value&quot;3、启动L，然后修改MySQL中数据，注意修改更新时间，然后稍等后查询K 中文分词 123456789https:&#x2F;&#x2F;github.com&#x2F;medcl&#x2F;elasticsearch-analysis-ikplugins目录下创建ik目录，解压到该目录GET _analyze?pretty &#123; &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;text&quot;:&quot;中国人民警察的服务宗旨&quot;&#125; Java操作Elasticsearch 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115 1、导入jar包 &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;&#x2F;groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;&#x2F;artifactId&gt; &lt;version&gt;7.6.2&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;&#x2F;groupId&gt; &lt;artifactId&gt;elasticsearch&lt;&#x2F;artifactId&gt; &lt;version&gt;7.6.2&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;2、编写代码@Componentpublic class ESRestService &#123; private RestHighLevelClient client; &#x2F;** * 根据索引名以及ID查询数据 * @param index 索引名称 * @param id 数据ＩＤ * @return *&#x2F; public String getDocument(String index, String id)&#123; GetResponse getResponse &#x3D; null; try&#123; client &#x3D; new RestHighLevelClient( RestClient.builder(new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;))); GetRequest getRequest &#x3D; new GetRequest(index,&quot;_doc&quot;, id ); getResponse &#x3D; client.get(getRequest, RequestOptions.DEFAULT); System.out.println(JSONObject.toJSONString(getResponse)); client.close(); &#125;catch(IOException e)&#123; e.printStackTrace(); &#125; return JSONObject.toJSONString(getResponse); &#125; &#x2F;** * 进行全文检索 * @param index * @param value * @param current * @param size * @return *&#x2F; public String keywordSearch(String index, String value, int current, int size)&#123; List&lt;Map&lt;String, Object&gt;&gt; result &#x3D; null; try&#123; client &#x3D; new RestHighLevelClient( RestClient.builder(new HttpHost(&quot;127.0.0.1&quot;, 9200, &quot;http&quot;))); SearchRequest searchRequest &#x3D; new SearchRequest(); searchRequest.indices(index); SearchSourceBuilder searchSourceBuilder &#x3D; new SearchSourceBuilder(); &#x2F;&#x2F;支持全词搜索的字段有：keywordName，keywordAuthor&quot; searchSourceBuilder.query(QueryBuilders .multiMatchQuery(value, &quot;name&quot;)); searchSourceBuilder.from(current); searchSourceBuilder.size(size); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse &#x3D; client.search(searchRequest, RequestOptions.DEFAULT); System.out.println(JSONObject.toJSONString(searchResponse)); &#x2F;&#x2F;处理返回结果 result &#x3D; dealResult(searchResponse.getHits()); client.close(); &#125;catch(IOException e)&#123; e.printStackTrace(); &#125; return JSONObject.toJSONString(result); &#125; &#x2F;** * 进行分页检索 * @param index * @param current * @param size * @return * @throws IOException *&#x2F; public String searchAll(String index, int current, int size) throws IOException &#123; client &#x3D; new RestHighLevelClient( RestClient.builder(new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;))); SearchRequest searchRequest &#x3D; new SearchRequest(index); SearchSourceBuilder searchSourceBuilder &#x3D; new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery()); searchSourceBuilder.from(current); searchSourceBuilder.size(size); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse &#x3D; client.search(searchRequest, RequestOptions.DEFAULT); System.out.println(JSONObject.toJSONString(searchResponse)); &#x2F;&#x2F;处理返回结果 SearchHits hits &#x3D; searchResponse.getHits(); client.close(); return JSONObject.toJSONString(hits); &#125; private List&lt;Map&lt;String, Object&gt;&gt; dealResult(SearchHits hits)&#123; List&lt;Map&lt;String, Object&gt;&gt; result &#x3D; new ArrayList&lt;&gt;(); for (SearchHit hit : hits.getHits()) &#123; Map&lt;String, Object&gt; map &#x3D; hit.getSourceAsMap(); result.add(map); &#125; return result; &#125;&#125;","categories":[],"tags":[]},{"title":"Elasticsearch使用(1)","slug":"Elasticsearch使用(1)","date":"2020-06-15T07:28:52.211Z","updated":"2020-05-27T03:10:20.149Z","comments":true,"path":"2020/06/15/Elasticsearch使用(1)/","link":"","permalink":"http://yoursite.com/2020/06/15/Elasticsearch%E4%BD%BF%E7%94%A8(1)/","excerpt":"","text":"Elasticsearch 也是基于 Lucene 的搜索引擎应用服务器，采用简单的 RESTfulAPI 来隐藏 Lucene 的复杂性。除此之外，Elasticsearch 对分布式部署提供了很好 的支持，用户不需要过度关注分布式设计的细节，即可实现分布式搜索引擎系统的搭建。因 此本次大觅网开发选用 Elasticsearch 做为搜索引擎服务器来实现商品搜索功能。 总结来说：Elasticsearch 是一个分布式的搜索引擎 其中的相关概念： node节点：单个的Elaticsearch服务器 index索引：相当于关系型数据库中的数据库，注意索引名称小写 document文档：索引中的单条记录称为文档，文档使用的是JSON格式表示 type类型：虚拟的逻辑分组，用于过滤文档，相当于MySQL中的表，不同的是type中只能存储一种数据 文档元数据：文档元数据为 _index, _type，_id，三者用于表示一个文档，index表示文档存放，type表示文档对象类型， id为文档的唯一标识 安装Elaticsearch注意： ​ 1、三个软件版本号要一致 ​ 2、需要先安装JDK环境 下载安装包 解压，在bin目录下双击运行elasticsearch.bat命令，运行完成后访问 http://127.0.0.1:9200/ 端口 获得一个JSON字符串响应说明安装成功，这个是ES的集群信息 然后接下来安装ES的管理工具，有的公司使用的是head组件，其实一个kibana也可以搞定 安装kibana Kibana是一个针对Elasticsearch的开源分析及可视化平台，常提到的大数据日志处理组件ELK里的K ，用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana，可以通过各种图表进行高级数据分析及展示。 下载完成后解压，进入config目录下修改kibana.yml文件，主要注意修改的 1234# ES 的地址，注意可以是集群地址elasticsearch.hosts: [&quot;http:&#x2F;&#x2F;localhost:9200&quot;] # kibana 的语言，修改后展示的是中文界面i18n.locale: &quot;zh-CN&quot; 访问http://localhost:5601 安装logstash用于同步数据源，属于ELK中的L， 将各种格式各种渠道的数据通过它收集解析之后格式化输出到 Elasticsearch ，最后再由 Kibana 提供的比较友好的 Web 界面进行汇总、分析、搜索 下载，解压，注意版本 在bin目录下创建mysqltoes.conf文件用于查询数据库 123456789101112131415161718192021222324252627282930313233# 读取数据input &#123; stdin &#123; &#125; jdbc &#123; jdbc_connection_string &#x3D;&gt; &quot;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;ssm&quot; jdbc_user &#x3D;&gt; &quot;root&quot; jdbc_password &#x3D;&gt; &quot;root&quot; jdbc_driver_library &#x3D;&gt; &quot;D:&#x2F;ELK&#x2F;logstash-7.6.2&#x2F;bin&#x2F;mysql-connector-java-5.1.38.jar&quot; jdbc_driver_class &#x3D;&gt; &quot;com.mysql.jdbc.Driver&quot; jdbc_paging_enabled &#x3D;&gt; &quot;true&quot; jdbc_page_size &#x3D;&gt; &quot;50000&quot; statement &#x3D;&gt; &quot;SELECT * FROM &#96;user&#96;&quot; schedule &#x3D;&gt; &quot;* * * * *&quot; &#125; &#125; output &#123; stdout &#123; codec &#x3D;&gt; json_lines &#125; elasticsearch &#123; hosts &#x3D;&gt; &quot;localhost:9200&quot; index &#x3D;&gt; &quot;test_user&quot; document_type &#x3D;&gt; &quot;_doc&quot; document_id &#x3D;&gt; &quot;%&#123;id&#125;&quot; &#125;&#125; 12logstash -f mysqltoes.conf一致开着就好，当数据库发生更改是，Elasticsearch中索引也会跟着更新 常规操作GET：以 GET 方式进行请求，一般用于数据查询。 POST：以 POST 方式进行请求，一般用于查询数据、有时也用作新增数据和修改数据。 PUT：以 PUT 方式进行请求，一般用于添加数据、修改数据。 DELETE：以 DELETE 方式进行请求，一般用于删除数据。 123456789101112131415161718添加索引PUT &#x2F;test1 &#123; &quot;settings&quot;:&#123; &quot;number_of_shards&quot;:3, &quot;number_of_replicas&quot;:2 &#125;, &quot;mappings&quot;: &#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125; &#125; &#125;&#125;删除索引DELETE 索引名 文档操作 12345678910111213新增文档POST &#x2F;test1&#x2F;_doc &#123; &quot;name&quot;:&quot;asd&quot;&#125;获取 GET &#x2F;test1&#x2F;_doc&#x2F;nTm5kXEBLntOdeBcP3FH改PUT &#x2F;test1&#x2F;_doc&#x2F;nTm5kXEBLntOdeBcP3FH&#123; &quot;name&quot;:&quot;hello&quot;&#125; 查询操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374查询所有GET &#x2F;goods1&#x2F;_searchmatch 子句 用于匹配度查询GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;name&quot;: &quot;asd&quot; &#125; &#125;&#125;term 精准查询term ？？？ GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;name&quot;: &quot;asd&quot; &#125; &#125;&#125;range 对比大小 “gte”表示”大于等于”、”lte”表示“小于等于”GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;range&quot;: &#123; &quot;age&quot;: &#123; “gte”:... ”lte”:... &#125; &#125; &#125;&#125;多个条件查询must：文档必须匹配这些条件才能被包含进来。must_not：文档必须不匹配这些条件才能被包含进来。should：如果文档满足 should 内的条件，将为该文档增加_score，否则，无任何影响GET &#x2F;test1&#x2F;_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;name&quot;:&quot;asd&quot; &#125; &#125; ] &#125; &#125;&#125;使用from和size命令分页GET &#x2F;test1&#x2F;_search&#123; &quot;from&quot;: 0, &quot;size&quot;: 20, &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must_not&quot;: [ &#123; &quot;match&quot;: &#123; &quot;name&quot;:&quot;asd&quot; &#125; &#125; ] &#125; &#125;&#125; mysql增量更新 123456781、修改数据库，增加时间列update_date，这里列主要用于记录数据更新时间，然后根据更新时间作为条件判断，判断是否更新数据到ES2、修改config配置use_column_value &#x3D;&gt; falsejdbc_default_timezone &#x3D;&gt;&quot;Asia&#x2F;Shanghai&quot;statement &#x3D;&gt; &quot;SELECT * FROM &#96;user&#96; update_date &gt; :sql_last_value&quot;3、启动L，然后修改MySQL中数据，注意修改更新时间，然后稍等后查询K 中文分词 123456https:&#x2F;&#x2F;github.com&#x2F;medcl&#x2F;elasticsearch-analysis-ikGET _analyze?pretty &#123; &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;text&quot;:&quot;中国人民警察的服务宗旨&quot;&#125; Java操作Elasticsearch 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899@Componentpublic class ESRestService &#123; private RestHighLevelClient client; &#x2F;** * 根据索引名以及ID查询数据 * @param index 索引名称 * @param id 数据ＩＤ * @return *&#x2F; public String getDocument(String index, String id)&#123; GetResponse getResponse &#x3D; null; try&#123; client &#x3D; new RestHighLevelClient( RestClient.builder(new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;))); GetRequest getRequest &#x3D; new GetRequest(index,&quot;_doc&quot;, id ); getResponse &#x3D; client.get(getRequest, RequestOptions.DEFAULT); System.out.println(JSONObject.toJSONString(getResponse)); client.close(); &#125;catch(IOException e)&#123; e.printStackTrace(); &#125; return JSONObject.toJSONString(getResponse); &#125; &#x2F;** * 进行全文检索 * @param index * @param value * @param current * @param size * @return *&#x2F; public String keywordSearch(String index, String value, int current, int size)&#123; List&lt;Map&lt;String, Object&gt;&gt; result &#x3D; null; try&#123; client &#x3D; new RestHighLevelClient( RestClient.builder(new HttpHost(&quot;127.0.0.1&quot;, 9200, &quot;http&quot;))); SearchRequest searchRequest &#x3D; new SearchRequest(); searchRequest.indices(index); SearchSourceBuilder searchSourceBuilder &#x3D; new SearchSourceBuilder(); &#x2F;&#x2F;支持全词搜索的字段有：keywordName，keywordAuthor&quot; searchSourceBuilder.query(QueryBuilders .multiMatchQuery(value, &quot;name&quot;)); searchSourceBuilder.from(current); searchSourceBuilder.size(size); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse &#x3D; client.search(searchRequest, RequestOptions.DEFAULT); System.out.println(JSONObject.toJSONString(searchResponse)); &#x2F;&#x2F;处理返回结果 result &#x3D; dealResult(searchResponse.getHits()); client.close(); &#125;catch(IOException e)&#123; e.printStackTrace(); &#125; return JSONObject.toJSONString(result); &#125; &#x2F;** * 进行分页检索 * @param index * @param current * @param size * @return * @throws IOException *&#x2F; public String searchAll(String index, int current, int size) throws IOException &#123; client &#x3D; new RestHighLevelClient( RestClient.builder(new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;))); SearchRequest searchRequest &#x3D; new SearchRequest(index); SearchSourceBuilder searchSourceBuilder &#x3D; new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchAllQuery()); searchSourceBuilder.from(current); searchSourceBuilder.size(size); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse &#x3D; client.search(searchRequest, RequestOptions.DEFAULT); System.out.println(JSONObject.toJSONString(searchResponse)); &#x2F;&#x2F;处理返回结果 SearchHits hits &#x3D; searchResponse.getHits(); client.close(); return JSONObject.toJSONString(hits); &#125; private List&lt;Map&lt;String, Object&gt;&gt; dealResult(SearchHits hits)&#123; List&lt;Map&lt;String, Object&gt;&gt; result &#x3D; new ArrayList&lt;&gt;(); for (SearchHit hit : hits.getHits()) &#123; Map&lt;String, Object&gt; map &#x3D; hit.getSourceAsMap(); result.add(map); &#125; return result; &#125;&#125;","categories":[],"tags":[]},{"title":"vue与后台交互","slug":"vue与后台交互","date":"2020-06-15T07:28:52.209Z","updated":"2020-05-29T02:16:59.043Z","comments":true,"path":"2020/06/15/vue与后台交互/","link":"","permalink":"http://yoursite.com/2020/06/15/vue%E4%B8%8E%E5%90%8E%E5%8F%B0%E4%BA%A4%E4%BA%92/","excerpt":"","text":"组件与父页的交互 ​ 展示 image-20200529101428794 ​ 交互发送请求 image-20200529101449588 vue2.6后的vue.config.js配置 ​ image-20200529101628505 vue不断请求报错处理 ​ image-20200529101652171","categories":[],"tags":[]},{"title":"vue项目实战~编写商城项目（0）~软件安装","slug":"vue项目实战~编写商城项目（0）~软件安装","date":"2020-06-15T07:28:52.207Z","updated":"2020-05-27T03:11:23.596Z","comments":true,"path":"2020/06/15/vue项目实战~编写商城项目（0）~软件安装/","link":"","permalink":"http://yoursite.com/2020/06/15/vue%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98~%E7%BC%96%E5%86%99%E5%95%86%E5%9F%8E%E9%A1%B9%E7%9B%AE%EF%BC%880%EF%BC%89~%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/","excerpt":"","text":"做项目前先把相关软件安装完毕，软件安装包括 nodewebspackvue-cligitwebstorm 1、node安装运行在服务端的 JavaScript，让JavaScript可以做后端程序员的时，编写自己的服务端，在使用Vue脚手架编写程序时需要用到node的环境，所以这里需要安装下，安装十分简单，直接运行node-v10.16.2-x64.msi即可，当然注意他的安装位置，安装完成后，打开控制台（菜单按键+r然后输入cmd然后回车）输入命令 node -v如果有就会输出node版本号，没有的话说明安装错误，需要重新安装 npm：全称为Node Package Manager，是一个基于Node.js的包管理器，也是整个Node.js社区最流行、支持的第三方模块最多的包管理器(类似于java中的Maven)。安装Node后会包含npm，在控制台敲 npm -v查看是否提示版本信息，没有的话需要重新安装，然后开始下一步 2、更换淘宝镜像安装命令：npm install -g cnpm –registry=https://registry.npm.taobao.org安装完成后验证：cnpm -v 3、webpack安装webpack一个打包工具，主要作用是把一些不能直接运行的扩展语言打包成浏览器可以使用的格式，所以这里需要安装下，打开控制台，运行下面命令： npm install webpack -g3、开始安装VUE运行下面的命令在控制台 npm install vue-cli --g 安装完成后输入验证安装是否完成（V是大写） vue -V 4、安装GitGit，是一个开源的分布式版本控制系统，主要用于管理项目版本，双击安装包Git-2.23.0-64-bit.exe即可，注意安装位置 5、webstorm安装是jetbrains公司旗下一款JavaScript 开发工具。目前已经被广大中国JS开发者誉为“Web前端开发神器”，进入下载包，进行安装，双击进入压缩包webstorm2019pj_downcc.com，找到WebStorm2019.1_downcc.com.exe可执行文件，双击开始安装，安装完成后开始选择自己喜欢的风格（建议选黑色），和相关组件。 选择完成后开始破解工具，首先断网，然后选择中间的那个选项，填入下面的注册码 注册码: 56ZS5PQ1RF-eyJsaWNlbnNlSWQiOiI1NlpTNVBRMVJGIiwibGljZW5zZWVOYW1lIjoi5q2j54mI5o6I5p2DIC4iLCJhc3NpZ25lZU5hbWUiOiIiLCJhc3NpZ25lZUVtYWlsIjoiIiwibGljZW5zZVJlc3RyaWN0aW9uIjoiRm9yIGVkdWNhdGlvbmFsIHVzZSBvbmx5IiwiY2hlY2tDb25jdXJyZW50VXNlIjpmYWxzZSwicHJvZHVjdHMiOlt7ImNvZGUiOiJJSSIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IkFDIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiRFBOIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiUFMiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJHTyIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IkRNIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiQ0wiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJSUzAiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJSQyIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IlJEIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiUEMiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJSTSIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IldTIiwicGFpZFVwVG8iOiIyMDIwLTAzLTEwIn0seyJjb2RlIjoiREIiLCJwYWlkVXBUbyI6IjIwMjAtMDMtMTAifSx7ImNvZGUiOiJEQyIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9LHsiY29kZSI6IlJTVSIsInBhaWRVcFRvIjoiMjAyMC0wMy0xMCJ9XSwiaGFzaCI6IjEyMjkxNDk4LzAiLCJncmFjZVBlcmlvZERheXMiOjAsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-SYSsDcgL1WJmHnsiGaHUWbaZLPIe2oI3QiIneDtaIbh/SZOqu63G7RGudSjf3ssPb1zxroMti/bK9II1ugHz/nTjw31Uah7D0HqeaCO7Zc0q9BeHysiWmBZ+8bABs5vr25GgIa5pO7CJhL7RitXQbWpAajrMBAeZ2En3wCgNwT6D6hNmiMlhXsWgwkw2OKnyHZ2dl8yEL+oV5SW14t7bdjYGKQrYjSd4+2zc4FnaX88yLnGNO9B3U6G+BuM37pxS5MjHrkHqMTK8W3I66mIj6IB6dYXD5nvKKO1OZREBAr6LV0BqRYSbuJKFhZ8nd6YDG20GvW6leimv0rHVBFmA0w==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQAF8uc+YJOHHwOFcPzmbjcxNDuGoOUIP+2h1R75Lecswb7ru2LWWSUMtXVKQzChLNPn/72W0k+oI056tgiwuG7M49LXp4zQVlQnFmWU1wwGvVhq5R63Rpjx1zjGUhcXgayu7+9zMUW596Lbomsg8qVve6euqsrFicYkIIuUu4zYPndJwfe0YkS5nY72SHnNdbPhEnN8wcB2Kz+OIG0lih3yz5EqFhld03bGp222ZQCIghCTVL6QBNadGsiN/lWLl4JdR3lJkZzlpFdiHijoVRdWeSWqM4y0t23c92HXKrgppoSV18XMxrWVdoSM3nuMHwxGhFyde05OdDtLpCv+jlWf5REAHHA201pAU6bJSZINyHDUTB+Beo28rRXSwSh3OUIvYwKNVeoBY+KwOJ7WnuTCUq1meE6GkKc4D/cXmgpOyW/1SmBz3XjVIi/zprZ0zf3qH5mkphtg6ksjKgKjmx1cXfZAAX6wcDBNaCL+Ortep1Dh8xDUbqbBVNBL4jbiL3i3xsfNiyJgaZ5sX7i8tmStEpLbPwvHcByuf59qJhV/bZOl8KqJBETCDJcY6O2aqhTUy+9x93ThKs1GKrRPePrWPluud7ttlgtRveit/pcBrnQcXOl1rHq7ByB8CFAxNotRUYL9IF5n3wJOgkPojMy6jetQA5Ogc8Sm7RG6vg1yow== 6、安装完成截止到这里，相关软件就全部安装完成了，打开webstorm后选择新建项目，选择创建Vue项目，接下来一路next即可，注意选择自己的项目名 7、遇到异常failed to download repo vuejs-templates/webpack环境安装有问题，以此在控制台敲打命令看出现的内容检查node安装是否正常 1.node -v检查Vue安装是否正常 2.vue -V (没有显示版本，npm i vue-cli -g)检查webpack安装是否正常 3.webpack -v(需要重新安装,npm install webpack -g)","categories":[],"tags":[]},{"title":"springCloud系列（5）之Config远程配置文件","slug":"springCloud系列（5）之Config远程配置文件","date":"2020-06-15T07:28:52.205Z","updated":"2020-05-27T03:10:02.957Z","comments":true,"path":"2020/06/15/springCloud系列（5）之Config远程配置文件/","link":"","permalink":"http://yoursite.com/2020/06/15/springCloud%E7%B3%BB%E5%88%97%EF%BC%885%EF%BC%89%E4%B9%8BConfig%E8%BF%9C%E7%A8%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","excerpt":"","text":"在微服务的项目中，经常会有很多的的配置文件，为减少配置文件的处理，这时候会使用springCloud中的config模块进行开发处理， Config分为server服务端和client客户端，我们需要服务端从远程工具上（git，SVN，码云）下载需要的配置，然后客户端获取这些配置，使用配置 一般情况下直接重启客户端会自动拉出新的配置，如果是想不启动刷新，则需要配置，注意当前我的spring Cloud版本是2.0.0 1、在码云上编写配置文件 config-dev.yml ，其实就是一个普通的配置文件，配置文件名上最好加-，这样方便后面配置文件的编写 1234567891011121314151617server: port: 8085spring: application: name: user-provider datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;ssm?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false password: root username: rootmybatis: type-aliases-package: com.lihao mapper-locations: classes:mapper&#x2F;*Mapper.xmleureka: client: service-url: defaultZone: http:&#x2F;&#x2F;root:123456@localhost:7776&#x2F;eureka&#x2F; 2、编写config-server项目负责从码云上下载对应配置 首先在原来的springCloud项目依赖前提下增加新的依赖 12345&lt;!-- config --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 增加配置文件application.yml 12345678910111213141516server: port: 7000spring: application: name: config-server cloud: config: server: git: uri: https:&#x2F;&#x2F;gitee.com&#x2F;lihao2&#x2F;config-server.git username: 1107156171@qq.com password: lihao6281633393eureka: client: service-url: defaultZone: http:&#x2F;&#x2F;root:123456@localhost:7776&#x2F;eureka&#x2F; 启动后访问http://localhost:7000/config-dev.yml 可以看到自己写的配置文件内容说明成功 3、编写config-client 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 在resources目录下创建bootstrap.yml文件 12345678910注意name的值和profile的值就是在Git中配置文件的名称我的配置文件名是config-dev，所以下面的name值是config，profile的值是devspring: application: name: config cloud: config: uri: http:&#x2F;&#x2F;localhost:7000&#x2F; profile: dev","categories":[],"tags":[]},{"title":"springCloud系列（5）之Config远程配置文件(1)","slug":"springCloud系列（5）之Config远程配置文件(1)","date":"2020-06-15T07:28:52.202Z","updated":"2020-05-27T03:10:19.145Z","comments":true,"path":"2020/06/15/springCloud系列（5）之Config远程配置文件(1)/","link":"","permalink":"http://yoursite.com/2020/06/15/springCloud%E7%B3%BB%E5%88%97%EF%BC%885%EF%BC%89%E4%B9%8BConfig%E8%BF%9C%E7%A8%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6(1)/","excerpt":"","text":"在微服务的项目中，经常会有很多的的配置文件，为减少配置文件的处理，这时候会使用springCloud中的config模块进行开发处理， Config分为server服务端和client客户端，我们需要服务端从远程工具上（git，SVN，码云）下载需要的配置，然后客户端获取这些配置，使用配置 一般情况下直接重启客户端会自动拉出新的配置，如果是想不启动刷新，则需要配置，注意当前我的spring Cloud版本是2.0.0 1、在码云上编写配置文件 config-dev.yml ，其实就是一个普通的配置文件，配置文件名上最好加-，这样方便后面配置文件的编写 1234567891011121314151617server: port: 8085spring: application: name: user-provider datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;ssm?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8&amp;useSSL&#x3D;false password: root username: rootmybatis: type-aliases-package: com.lihao mapper-locations: classes:mapper&#x2F;*Mapper.xmleureka: client: service-url: defaultZone: http:&#x2F;&#x2F;root:123456@localhost:7776&#x2F;eureka&#x2F; 2、编写config-server项目负责从码云上下载对应配置 首先在原来的springCloud项目依赖前提下增加新的依赖 12345&lt;!-- config --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 增加配置文件application.yml 12345678910111213141516server: port: 7000spring: application: name: config-server cloud: config: server: git: uri: https:&#x2F;&#x2F;gitee.com&#x2F;lihao2&#x2F;config-server.git username: 1107156171@qq.com password: lihao6281633393eureka: client: service-url: defaultZone: http:&#x2F;&#x2F;root:123456@localhost:7776&#x2F;eureka&#x2F; 在启动类上添加@EnableConfigServer注解，最后运行启动类 启动后访问http://localhost:7000/config-dev.yml 可以看到自己写的配置文件内容说明成功 3、编写config-client 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 在resources目录下创建bootstrap.yml文件 12345678910注意name的值和profile的值就是在Git中配置文件的名称我的配置文件名是config-dev，所以下面的name值是config，profile的值是devspring: application: name: config cloud: config: uri: http:&#x2F;&#x2F;localhost:7000&#x2F; profile: dev 4、有的时候需要直接更改配置，但是这时候不能直接使用，需要重启服务，下面的配置主要是完成不重启项目，直接手动刷新配置。 在远程gitee上添加profile属性，什么值无所谓，主要用于展示刷新配置的效果 1profile： one 在config-client中添加jar包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 在配置文件bootstrap.yml添加下面的设置，取消springBoot验证 123management: security: enabled: false 最后是controller类 1234567891011121314@RestController@RefreshScopepublic class UserService &#123; &#x2F;&#x2F; 获取配置中的profile值，并注入 @Value(&quot;$&#123;profile&#125;&quot;) private String profile; @RequestMapping(&quot;t&quot;) public String test()&#123; System.out.println(profile); return &quot;success&quot;; &#125;&#125; 然后测试 首先所有都启动，然后修改远程中profile的值，然后访问 /refresh 路径，注意访问方式是POST","categories":[],"tags":[]},{"title":"springCloud系列（4）之Ribbon负载均衡","slug":"springCloud系列（4）之Ribbon负载均衡","date":"2020-06-15T07:28:52.198Z","updated":"2020-05-27T03:10:33.532Z","comments":true,"path":"2020/06/15/springCloud系列（4）之Ribbon负载均衡/","link":"","permalink":"http://yoursite.com/2020/06/15/springCloud%E7%B3%BB%E5%88%97%EF%BC%884%EF%BC%89%E4%B9%8BRibbon%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","excerpt":"","text":"Ribbon负载均衡是一个基于客户端的负载均衡，当发送请求时会读取 Eureka Server 中的服务列表，然后根据负载均衡策略进行访问。 首先做好准备操作，我们需要一个消费者，两个生产者，注意生产者的names属性是一致的 在消费者端添加下面的配置，然后访问消费者的controller路径就好 1、jar包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 2、yml配置 123user-provider: #客户端名称 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule #负载均衡策略 常用的负载均衡策略 WeightedResponseTimeRule 根据响应时间分配一个weight（权重），响应时间越长，weight*越小，被选中的可能性越低 RoundRobinRule 轮询选择server此为默认的负载均衡策略 RandomRule 随机选择一个server ZoneAvoidanceRule 复合判断server所在区域的性能和server的可用性选择server RetryRule 在一个配置时间段内，当选择server不成功时一直尝试重新选择 BestAvailableRule 选择一个并发请求最小的server AvailabilityFilteringRule 过滤掉那些因为一直连接失败而被标记为circuit tripped的server，并过滤掉那些高并发的*server（active connections超过配置的阈值）","categories":[],"tags":[]}],"categories":[],"tags":[]}